{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1Ô∏è‚É£ What Is Statistical Learning?\n",
        "\n",
        "Statistical learning is about learning patterns from data.\n",
        "We generally have two main components:\n",
        "* **Inputs (features):** usually written as $X$\n",
        "* **Output (target):** usually written as $Y$\n",
        "\n",
        "We assume there is a hidden, true relationship between them:\n",
        "\n",
        "$$\n",
        "Y = f(X) + \\epsilon\n",
        "$$\n",
        "\n",
        "### üîç Explanation of Symbols\n",
        "* **$Y$**: The output we care about (e.g., sales, marks, house price).\n",
        "* **$X$**: One feature or a collection of features (e.g., hours studied, house size, location).\n",
        "* **$f(X)$**: The **true but unknown function** that links $X$ to $Y$. This is the \"signal.\"\n",
        "* **$\\epsilon$ (epsilon)**: Random **noise**. These are things we can‚Äôt measure or control (luck, mood, measurement errors).\n",
        "\n",
        "**Our job in statistical learning is to use data to estimate $f$.**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "### üí° Simple Examples\n",
        "\n",
        "**1. Study vs Marks**\n",
        "* $X$ = hours of study\n",
        "* $Y$ = exam score\n",
        "$$\n",
        "\\text{Score} = f(\\text{Hours}) + \\epsilon\n",
        "$$\n",
        "\n",
        "**2. House Features vs Price**\n",
        "* $X$ = (area in sq ft, number of bedrooms, distance to metro)\n",
        "* $Y$ = house price\n",
        "$$\n",
        "\\text{Price} = f(\\text{Area, Bedrooms, Distance}) + \\epsilon\n",
        "$$\n",
        "\n",
        "*In practice, we never know the true $f$, but we estimate it using data!*"
      ],
      "metadata": {
        "id": "OwC2EgS7PxEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2Ô∏è‚É£ Why Do We Estimate $f(X)$? (Prediction vs Inference)\n",
        "\n",
        "We estimate $f(X)$ mainly for two reasons:\n",
        "\n",
        "## A. Prediction üéØ\n",
        "We learn an estimate of the true function $f$ and call it $\\hat f$ (pronounced \"f-hat\").\n",
        "For a new input $X$, our prediction is:\n",
        "\n",
        "$$\n",
        "\\hat Y = \\hat f(X)\n",
        "$$\n",
        "\n",
        "* **$\\hat f(X)$**: The function we learned (e.g., a Linear Regression model).\n",
        "* **$\\hat Y$**: The predicted value.\n",
        "\n",
        "**Example:**\n",
        "Given a student with 5 hours of study, we plug $X = 5$ into $\\hat f$:\n",
        "$$\n",
        "\\hat Y = \\hat f(5) \\quad \\text{(This is our predicted score)}\n",
        "$$\n",
        "*Goal: Minimize the difference between $\\hat Y$ and true $Y$.*\n",
        "\n",
        "## B. Inference üîç\n",
        "Here, we don't just want a number; we want to **understand the relationship**.\n",
        "\n",
        "**Typical questions:**\n",
        "* Does increasing TV ads increase sales more than radio ads?\n",
        "* Which features are the most important?\n",
        "* Is the relationship positive or negative?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### üìâ Reducible vs Irreducible Error\n",
        "Even with a perfect model, predictions are never 100% accurate because of noise ($\\epsilon$).\n",
        "The expected squared error is:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}\\left[(Y - \\hat Y)^2\\right] = \\underbrace{[f(X) - \\hat f(X)]^2}_{\\text{Reducible Error}} + \\underbrace{\\text{Var}(\\epsilon)}_{\\text{Irreducible Error}}\n",
        "$$\n",
        "\n",
        "| Error Type | Meaning | Can we fix it? |\n",
        "| :--- | :--- | :--- |\n",
        "| **Reducible** | Error because our model $\\hat f$ isn't perfect. | **Yes**, by using better algorithms/data. |\n",
        "| **Irreducible** | Error caused by natural noise ($\\epsilon$) in the world. | **No**, this is pure randomness. |"
      ],
      "metadata": {
        "id": "F4Xg2yRmP052"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3Ô∏è‚É£ Parametric Methods (Assume a Formula)\n",
        "\n",
        "Parametric methods involve a two-step process:\n",
        "1.  **Assume a shape** for $f(X)$ (usually a line).\n",
        "2.  **Estimate the parameters** (coefficients) from the data.\n",
        "\n",
        "The most common is the **Linear Model**:\n",
        "\n",
        "$$\n",
        "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p + \\epsilon\n",
        "$$\n",
        "\n",
        "### üìù Explanation of Symbols\n",
        "* **$\\beta_0$**: Intercept (baseline value of $Y$ when all $X$ are 0).\n",
        "* **$\\beta_1 \\dots \\beta_p$**: Coefficients (the effect of each feature on $Y$).\n",
        "* **$p$**: Number of features.\n",
        "\n",
        "We use training data to find the best values for $\\beta$. The most common method is **Least Squares**.\n",
        "\n",
        "\n",
        "\n",
        "[Image of linear regression fitted line through data points]\n",
        "\n",
        "\n",
        "### Example: Predicting Salary üí∞\n",
        "$$\n",
        "\\text{Salary} = \\beta_0 + \\beta_1 (\\text{Education}) + \\beta_2 (\\text{Experience}) + \\epsilon\n",
        "$$\n",
        "* **Interpretation of $\\beta_1$**: How much salary increases (on average) for every 1 extra year of education.\n",
        "\n",
        "### ‚úÖ Pros & ‚ùå Cons\n",
        "* **Pros:** Simple, fast, very easy to interpret (good for inference).\n",
        "* **Cons:** If the real world is complex (non-linear), this model will perform poorly (high bias)."
      ],
      "metadata": {
        "id": "zcU-gstxP2a7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4Ô∏è‚É£ Non-Parametric Methods (Let Data Decide)\n",
        "\n",
        "Non-parametric methods **do not** assume a fixed formula like a straight line. Instead, they try to fit the data points as closely as possible, allowing the data to determine the shape of the curve.\n",
        "\n",
        "We still write $Y \\approx \\hat f(X)$, but $\\hat f$ is flexible (e.g., K-Nearest Neighbors, Splines, Decision Trees).\n",
        "\n",
        "### Example: Study Hours vs Marks (Curved)\n",
        "* **Reality:** First 2‚Äì3 hours $\\to$ big improvement. After 9 hours $\\to$ no improvement (flattening).\n",
        "* A linear model forces a straight line (incorrect).\n",
        "* A non-parametric model bends to fit the curve.\n",
        "\n",
        "\n",
        "\n",
        "### ‚úÖ Pros & ‚ùå Cons\n",
        "* **Pros:** Very flexible, fits complex/weird patterns well.\n",
        "* **Cons:** Needs lots of data, harder to interpret, and high risk of **Overfitting**."
      ],
      "metadata": {
        "id": "Y-fyV5qCP3z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5Ô∏è‚É£ Overfitting (Too Good to be True)\n",
        "\n",
        "Overfitting happens when a model learns the **noise** in the training data rather than the **signal**.\n",
        "\n",
        "**Imagine we have 10 students:**\n",
        "* A very flexible model might draw a wiggly line that touches all 10 points perfectly (0% Training Error).\n",
        "* But for the 11th student (Test Data), the prediction is way off because the model was too focused on the specific quirks of the first 10 students.\n",
        "\n",
        "**Key Idea:**\n",
        "* **Overfitted Model:** Low Training Error, High Test Error.\n",
        "* **Good Model:** Balanced.\n",
        "\n",
        "\n",
        "\n",
        "[Image of underfitting vs overfitting plots]\n",
        "\n",
        "\n",
        "*Both parametric and non-parametric methods can overfit, but non-parametric methods are riskier because they are so flexible.*"
      ],
      "metadata": {
        "id": "dxo7CZzCP5l8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6Ô∏è‚É£ Flexibility vs. Interpretability Trade-off\n",
        "\n",
        "There is a classic trade-off in machine learning:\n",
        "* **Flexibility:** How curvy/complex can the model be?\n",
        "* **Interpretability:** How easy is it to explain *why* the model made a prediction?\n",
        "\n",
        "| Model Type | Flexibility | Interpretability | Examples |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Low Flex** | Low | **High** | Linear Regression, Lasso |\n",
        "| **Medium Flex** | Medium | Medium | GAMs (Generalized Additive Models) |\n",
        "| **High Flex** | **High** | Low (Black Box) | Random Forests, Neural Networks, SVMs |\n",
        "\n",
        "\n",
        "\n",
        "**Rule of Thumb:**\n",
        "* Care about **Understanding** (Inference)? $\\to$ Use Simpler Models.\n",
        "* Care about **Accuracy** (Prediction)? $\\to$ Use Flexible Models."
      ],
      "metadata": {
        "id": "5ekBG8G4P62f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7Ô∏è‚É£ Supervised vs. Unsupervised Learning\n",
        "\n",
        "### üÖ∞Ô∏è Supervised Learning\n",
        "We have both **Inputs ($X$)** and **Correct Answers ($Y$)**.\n",
        "* **Goal:** Learn a function $\\hat Y = \\hat f(X)$.\n",
        "* **Examples:** Predicting house prices (Regression), Email Spam detection (Classification).\n",
        "* *We \"supervise\" the model by checking its answers against the true $Y$.*\n",
        "\n",
        "### üÖ±Ô∏è Unsupervised Learning\n",
        "We only have **Inputs ($X$)**. We have **NO** labels ($Y$).\n",
        "* **Goal:** Find hidden structure or groups in the data.\n",
        "* **Typical Task:** **Clustering**.\n",
        "\n",
        "**Example:** Customer Segmentation\n",
        "We have data on: *Number of orders, Average cart value*.\n",
        "The algorithm might discover 3 groups:\n",
        "1.  Heavy Spenders\n",
        "2.  Occasional Buyers\n",
        "3.  Window Shoppers\n",
        "\n",
        "\n",
        "\n",
        "[Image of supervised classification vs unsupervised clustering]\n",
        "\n",
        "\n",
        "*Note: There is also **Semi-Supervised Learning**, where we have a small amount of labeled data and lots of unlabeled data.*"
      ],
      "metadata": {
        "id": "R_zTkTcCQ0Ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8Ô∏è‚É£ Regression vs. Classification\n",
        "\n",
        "We categorize supervised learning problems based on the **type of Output ($Y$)**.\n",
        "\n",
        "### 1. Regression ($Y$ is Numeric)\n",
        "The output is a continuous number.\n",
        "$$\n",
        "Y = f(X) + \\epsilon\n",
        "$$\n",
        "* **Examples:** Predicting stock price, temperature, blood sugar level.\n",
        "* **Methods:** Linear Regression, Regression Trees.\n",
        "\n",
        "### 2. Classification ($Y$ is Categorical)\n",
        "The output belongs to a specific class or category.\n",
        "$$\n",
        "Y \\in \\{ \\text{Class 1}, \\text{Class 2}, \\dots, \\text{Class K} \\}\n",
        "$$\n",
        "* **Examples:** Spam vs Not Spam ($K=2$), Cat vs Dog vs Horse ($K=3$).\n",
        "* **Methods:** Logistic Regression, KNN, SVM.\n",
        "\n",
        "\n",
        "\n",
        "**Crucial Note:** The inputs ($X$) can be the same for both.\n",
        "* Predict probability of rain (0.85) $\\to$ **Regression**.\n",
        "* Predict *will* it rain? (Yes/No) $\\to$ **Classification**."
      ],
      "metadata": {
        "id": "rVeO_oobP9zO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# üß† **2.2 Assessing Model Accuracy\n",
        "\n",
        "---\n",
        "\n",
        "# #Ô∏è‚É£ 2.2 Assessing Model Accuracy\n",
        "\n",
        "When we build a model, the BIG question is:\n",
        "\n",
        "üëâ **How do we know if our model is good?**\n",
        "\n",
        "To answer this, we measure **how close predictions are to real values**.\n",
        "We care mostly about **how well the model performs on new, unseen data** (not the data used for training!).\n",
        "\n",
        "---\n",
        "\n",
        "## ‚≠ê 2.2.1 Measuring the Quality of Fit\n",
        "\n",
        "### üéØ What is ‚ÄúQuality of Fit‚Äù?\n",
        "\n",
        "It‚Äôs simply **how well predictions match the actual values**.\n",
        "\n",
        "In **regression** models, the most common metric is:\n",
        "\n",
        "### üìå **Mean Squared Error (MSE)**\n",
        "\n",
        "When we perform regression (predicting a number, like stock price or height), we need a metric to see how far off our predictions are from reality. The most common metric is the **Mean Squared Error (MSE)**.\n",
        "\n",
        "#### üìò Formula\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{f}(x_i))^2\n",
        "$$\n",
        "\n",
        "### üîç What do the symbols mean?\n",
        "\n",
        "| Symbol                     | Meaning                       |\n",
        "| -------------------------- | ----------------------------- |\n",
        "| ( n )                      | Number of data points         |\n",
        "| $( y_i )$                    | Actual value for point *i*    |\n",
        "| $( \\hat{f}(x_i) )$           | Predicted value for point *i* |\n",
        "| $$((y_i - \\hat{f}(x_i))^2)$$ | Squared error for point *i*   |\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è **Training MSE vs Test MSE**\n",
        "\n",
        "### üèãÔ∏è **Training MSE**\n",
        "\n",
        "Computed on the **same data used to train** the model.\n",
        "It **always decreases** when the model becomes more flexible (more complicated).\n",
        "\n",
        "üìâ **Lower training MSE ‚â† better model**.\n",
        "\n",
        "### üöÄ **Test MSE**\n",
        "\n",
        "Computed on **new, unseen data**.\n",
        "This is what truly matters.\n",
        "\n",
        "---\n",
        "\n",
        "### üß©  Example\n",
        "\n",
        "Suppose a model predicts house prices.\n",
        "\n",
        "| House | Actual Price | Predicted | Error | Squared Error |\n",
        "| ----- | ------------ | --------- | ----- | ------------- |\n",
        "| 1     | 50           | 60        | -10   | 100           |\n",
        "| 2     | 80           | 70        | 10    | 100           |\n",
        "| 3     | 100          | 90        | 10    | 100           |\n",
        "\n",
        "MSE:\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{100 + 100 + 100}{3} = 100\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### üìâ Why Low Training MSE Can Be Misleading\n",
        "\n",
        "If a model is **too complicated**, it ‚Äúmemorizes‚Äù the training data.\n",
        "This is called **overfitting**.\n",
        "\n",
        "üìå Overfitted models look perfect on training data but fail badly on new data.\n",
        "\n",
        "Think of a student who memorizes answers but doesn‚Äôt actually understand anything.\n",
        "\n",
        "This is why **test MSE** typically shows a **U-shaped curve**:\n",
        "\n",
        "üìâ MSE decreases ‚Üí ‚úî\n",
        "üìâ MSE reaches a minimum ‚Üí best model\n",
        "üìà MSE increases again ‚Üí ‚ùå overfitting\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## ‚≠ê 2.2.2 The Bias‚ÄìVariance Trade-Off\n",
        "\n",
        "Probably the **most important concept in machine learning**.\n",
        "\n",
        "### üéØ Key Goal\n",
        "\n",
        "Choose a model that balances:\n",
        "\n",
        "* **Bias** (error from being too simple)\n",
        "* **Variance** (error from being too sensitive)\n",
        "\n",
        "This creates the famous **trade-off**.\n",
        "\n",
        "---\n",
        "\n",
        "Why does the Test MSE form that U-shape? It happens because of two competing forces: **Bias** and **Variance**. The total error in any model can be mathematically broken down into three parts.\n",
        "\n",
        "### üìå Formula for Expected Test MSE\n",
        "\n",
        "\n",
        "$$\n",
        "\\mathbb{E}[(y_0 - \\hat{f}(x_0))^2]\n",
        "= \\text{Var}(\\hat{f}(x_0))\n",
        "+ \\text{Bias}(\\hat{f}(x_0))^2\n",
        "+ \\text{Var}(\\varepsilon)\n",
        "$$\n",
        "\n",
        "\n",
        "### üîç Variables Explained\n",
        "\n",
        "| Term                        | Meaning                                                              |\n",
        "| --------------------------- | -------------------------------------------------------------------- |\n",
        "| $( y_0 )$                     | Actual value for a test point                                        |\n",
        "| $$(\\hat{f}(x_0))$$            | Predicted value for that test point                                  |\n",
        "| $(\\text{Var}(\\hat{f}))$     | How much the model‚Äôs prediction changes with different training data |\n",
        "| $(\\text{Bias}^2)$           | How far the model‚Äôs predictions are from the true pattern            |\n",
        "| $(\\text{Var}(\\varepsilon))$ | Irreducible noise (cannot be eliminated by any model)                |\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Intuition\n",
        "\n",
        "* **High bias ‚Üí underfitting**\n",
        "  *Model too simple ‚Üí misses real patterns.*\n",
        "\n",
        "* **High variance ‚Üí overfitting**\n",
        "  *Model too sensitive ‚Üí sees patterns in noise.*\n",
        "\n",
        "Ideal model: **low bias + low variance**.\n",
        "\n",
        "---\n",
        "\n",
        "### üçï Real-Life Analogy\n",
        "\n",
        "Imagine predicting pizza delivery time.\n",
        "\n",
        "* **High bias (too simple model):**\n",
        "  \"Delivery always takes 30 minutes.\"\n",
        "  ‚Üí Bad for short or long deliveries.\n",
        "\n",
        "* **High variance (too complex model):**\n",
        "  \"Delivery depends on 20 factors: weather, chef mood, pizza toppings, etc.\"\n",
        "  ‚Üí Overreacting, unstable.\n",
        "\n",
        "* **Balanced model:**\n",
        "  \"Delivery depends mostly on distance + traffic.\"\n",
        "  ‚Üí Simple but accurate.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚≠ê 2.2.3 The Classification Setting\n",
        "\n",
        "Now we move from predicting numbers ‚Üí predicting categories.\n",
        "\n",
        "Examples:\n",
        "\n",
        "* Spam or Not Spam\n",
        "* Cancer or No Cancer\n",
        "* Loan Default or Not\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Training Error Rate (Classification)\n",
        "\n",
        "Formula:\n",
        "\n",
        "$$\n",
        "\\text{Training Error Rate}\n",
        "= \\frac{1}{n} \\sum_{i=1}^n I(y_i \\neq \\hat{y}_i)\n",
        "$$\n",
        "\n",
        "\n",
        "### Symbols:\n",
        "\n",
        "* $(\\hat{y}_i)$: predicted class\n",
        "* $(y_i )$: actual class\n",
        "* $(I(\\cdot))$: indicator function (1 if condition is true)\n",
        "\n",
        "---\n",
        "\n",
        "## ‚≠ê The Bayes Classifier\n",
        "\n",
        "(The perfect‚Äîbut impossible‚Äîclassifier)\n",
        "\n",
        "It chooses the class with the highest probability:\n",
        "\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\arg\\max_j \\; \\Pr(Y=j \\mid X=x_0)\n",
        "$$\n",
        "\n",
        "\n",
        "You usually **cannot compute this**, because you don‚Äôt know true probabilities.\n",
        "\n",
        "But it is the **gold standard**.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Bayes Error Rate (the minimum possible error)\n",
        "\n",
        "Even the ideal classifier cannot be perfect if classes naturally overlap.\n",
        "\n",
        "Formula:\n",
        "\n",
        "\n",
        "$$\n",
        "1 - \\mathbb{E}\\left[ \\max_j \\Pr(Y=j \\mid X) \\right]\n",
        "$$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## ‚≠ê K-Nearest Neighbors (KNN) Classifier\n",
        "\n",
        "Super simple idea:\n",
        "\n",
        "üëâ To classify a point, look at the **K closest training points**\n",
        "üëâ Take the **majority vote**\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Conditional Probability Estimate in KNN\n",
        "\n",
        "$$\n",
        "\\Pr(Y = j \\mid X = x_0)\n",
        "= \\frac{1}{K} \\sum_{i \\in N_0} I(y_i = j)\n",
        "$$\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( N_0 ): set of nearest K neighbors\n",
        "* ( I(\\cdot) ): 1 if neighbor belongs to class j\n",
        "\n",
        "---\n",
        "\n",
        " ### üéØ Effect of Choosing K\n",
        "\n",
        "* **Small K** ‚Üí very flexible ‚Üí low bias, high variance ‚Üí overfits\n",
        "* **Large K** ‚Üí less flexible ‚Üí high bias, low variance ‚Üí underfits\n",
        "\n",
        "The test error again forms a **U-shape**.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## ‚≠ê Extra Intuitive Example (Not from book)\n",
        "\n",
        "Imagine predicting if a person likes chai.\n",
        "\n",
        "You survey neighbors:\n",
        "\n",
        "### Case 1: K = 1\n",
        "\n",
        "You only ask the **closest neighbor**.\n",
        "‚Üí Very noisy\n",
        "‚Üí High variance\n",
        "\n",
        "### Case 2: K = 100\n",
        "\n",
        "You ask **100 people**, even far away.\n",
        "‚Üí Majority vote becomes too generic\n",
        "‚Üí High bias\n",
        "\n",
        "Best value of K is somewhere in the middle.\n",
        "\n",
        "---\n",
        "\n",
        " # üéâ Final Summary\n",
        "\n",
        "| Concept          | Meaning                       | Good / Bad                                 |\n",
        "| ---------------- | ----------------------------- | ------------------------------------------ |\n",
        "| Training MSE     | Error on training data        | Always low for complex models (misleading) |\n",
        "| Test MSE         | Error on new data             | What actually matters                      |\n",
        "| Bias             | Wrong assumptions             | Too simple = underfitting                  |\n",
        "| Variance         | Too sensitive to noise        | Too complex = overfitting                  |\n",
        "| Bayes Classifier | Theoretical best              | Not achievable in practice                 |\n",
        "| KNN              | Simple method using neighbors | K controls flexibility                     |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "kkLEkGBTVvRj"
      }
    }
  ]
}