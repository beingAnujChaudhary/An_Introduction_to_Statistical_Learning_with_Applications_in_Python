{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìò Chapter 1 ‚Äî Introduction  \n",
        "### *From \"An Introduction to Statistical Learning with Python\" (ISLP)*\n",
        "\n",
        "---\n",
        "\n",
        "This chapter introduces the **foundations of statistical learning**, its major types, key real-world examples, the history behind the field, and important notations that will be used throughout the book.\n",
        "\n",
        "It prepares you for the concepts that appear in later chapters such as supervised learning, classification, regression, resampling, regularization, tree methods, and unsupervised learning.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "KW3_SGhHQEHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç What Is Statistical Learning?\n",
        "\n",
        "**Statistical Learning** is a collection of tools used to:\n",
        "- Understand relationships between variables  \n",
        "- Make predictions  \n",
        "- Discover hidden patterns  \n",
        "- Handle high-dimensional data  \n",
        "- Quantify uncertainty  \n",
        "\n",
        "It is used across:\n",
        "- Business  \n",
        "- Medicine  \n",
        "- Finance  \n",
        "- Biology  \n",
        "- Technology  \n",
        "- Public policy  \n",
        "\n",
        "Statistical learning methods belong to two broad classes:\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ **1. Supervised Learning**\n",
        "We have:\n",
        "- **Inputs:** X  \n",
        "- **Output:** Y  \n",
        "Goal: **predict Y from X**\n",
        "\n",
        "Examples:\n",
        "- Predict wages (continuous)  \n",
        "- Predict stock movement (Up/Down)  \n",
        "- Predict medical outcomes  \n",
        "\n",
        "---\n",
        "\n",
        "### üéØ **2. Unsupervised Learning**\n",
        "We only have:\n",
        "- **Inputs:** X  \n",
        "- **No output variable**  \n",
        "\n",
        "Goal: **find structure**  \n",
        "Examples:\n",
        "- Customer segmentation  \n",
        "- Gene expression clustering  \n",
        "- PCA visualization  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9m0ZoK7UQFpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìà Example 1 ‚Äî Wage Data (Regression)\n",
        "\n",
        "We study wage patterns of men in the U.S. Atlantic region.\n",
        "\n",
        "### Key Insights:\n",
        "- Wage increases with age until about **60**, then declines  \n",
        "- Wage increases slightly from 2003‚Äì2009  \n",
        "- Higher education ‚Üí higher wage  \n",
        "\n",
        "### Why It Matters:\n",
        "This is a **regression** problem because the goal is to predict a **continuous output** (wage).\n",
        "\n",
        "**Important variables:**\n",
        "- Age  \n",
        "- Education level  \n",
        "- Year  \n",
        "\n",
        "Later chapters show how linear regression and non-linear models handle these relationships.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "__vidHZmQHS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìâ Example 2 ‚Äî Stock Market Data (Classification)\n",
        "\n",
        "Dataset: Daily percent changes in the S&P 500 (2001‚Äì2005).\n",
        "\n",
        "### Goal:\n",
        "Predict whether the market will go:\n",
        "- **Up**\n",
        "- **Down**\n",
        "\n",
        "### Insights:\n",
        "- Previous day's return does **not strongly predict** next day's return  \n",
        "- Lagged returns (2‚Äì5 days) show weak patterns  \n",
        "- A Quadratic Discriminant Analysis (QDA) model can achieve ~**60% accuracy**\n",
        "\n",
        "### Key Point:\n",
        "This is a **classification** problem because the output is **categorical**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "NYS6CHtaQItz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß¨ Example 3 ‚Äî Gene Expression Data (Unsupervised Learning)\n",
        "\n",
        "Dataset: **NCI60** (64 cancer cell lines, 6,830 gene expression measurements).\n",
        "\n",
        "### Goal:\n",
        "Discover **clusters** without using cancer type labels.\n",
        "\n",
        "### Steps:\n",
        "1. Apply **Principal Component Analysis (PCA)**  \n",
        "2. Reduce 6,830 variables ‚Üí **2 dimensions** (Z‚ÇÅ and Z‚ÇÇ)  \n",
        "3. Visualize clusters  \n",
        "\n",
        "### Insights:\n",
        "- Clear cluster formations appear  \n",
        "- Many clusters match cancer types, even though labels were not used  \n",
        "- Great demonstration of **unsupervised learning**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "AUHl4VOQQK_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìú A Brief History of Statistical Learning\n",
        "\n",
        "### Key Milestones:\n",
        "\n",
        "| Year | Method | Notes |\n",
        "|------|--------|-------|\n",
        "| 1800s | Least Squares | Foundation of linear regression |\n",
        "| 1936 | Linear Discriminant Analysis (LDA) | First major classification method |\n",
        "| 1940s | Logistic Regression | Widely used for binary outcomes |\n",
        "| 1970s | Generalized Linear Models (GLMs) | Unified regression family |\n",
        "| 1980s | Trees, GAMs | First practical non-linear models |\n",
        "| 1990s | Support Vector Machines (SVM) | Margin-based classification |\n",
        "| 2000s+ | Neural Networks & Deep Learning | High-flexibility non-linear models |\n",
        "\n",
        "Modern statistical learning grew due to:\n",
        "- Advances in computing  \n",
        "- Large datasets  \n",
        "- User-friendly software (Python, R)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "fiAQeyIHQM38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö The ISLP Book Approach\n",
        "\n",
        "ISLP is a **practical, intuition-first** version of the more theoretical ESL (Elements of Statistical Learning).\n",
        "\n",
        "It is built on four principles:\n",
        "\n",
        "---\n",
        "\n",
        "### **1Ô∏è‚É£ Focus on widely useful methods**\n",
        "Only the most practical & generalizable techniques.\n",
        "\n",
        "---\n",
        "\n",
        "### **2Ô∏è‚É£ Emphasize intuition over black-box use**\n",
        "Understand:\n",
        "- assumptions  \n",
        "- strengths  \n",
        "- weaknesses  \n",
        "- when to use each model  \n",
        "\n",
        "---\n",
        "\n",
        "### **3Ô∏è‚É£ Minimize mathematical burden**\n",
        "Requires:\n",
        "- basic stats  \n",
        "- light math  \n",
        "- little/no matrix algebra\n",
        "\n",
        "---\n",
        "\n",
        "### **4Ô∏è‚É£ Learn by doing (Python Labs)**\n",
        "Each chapter contains:\n",
        "- code examples  \n",
        "- visualizations  \n",
        "- application-focused labs  \n",
        "\n",
        "These labs are essential for building ML intuition.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "fJ2XsLrBQOYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üë• Who Should Read This Book?\n",
        "\n",
        "This book is ideal for:\n",
        "- Data Scientists  \n",
        "- Analysts  \n",
        "- Engineers  \n",
        "- Students (Masters, PhD, advanced undergraduates)  \n",
        "- People from business, biology, economics, psychology, CS  \n",
        "\n",
        "Requires:\n",
        "- basic statistics  \n",
        "- basic programming skills  \n",
        "- interest in understanding + applying ML  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "LsLFYpKeQQHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî¢ Notation Used in the Book\n",
        "\n",
        "### **Data Dimensions**\n",
        "\n",
        "- **n** ‚Äî number of observations  \n",
        "- **p** ‚Äî number of predictors  \n",
        "- **X** ‚Äî data matrix (n √ó p)  \n",
        "- **x·µ¢** ‚Äî ith observation (row vector)  \n",
        "- **x‚±º** ‚Äî jth feature (column vector)  \n",
        "- **y** ‚Äî output vector  \n",
        "\n",
        "---\n",
        "\n",
        "### **Matrix Representation**\n",
        "\n",
        "If X is the data matrix:\n",
        "\n",
        "\\[\n",
        "X =\n",
        "\\begin{pmatrix}\n",
        "x_{11} & x_{12} & \\dots & x_{1p} \\\\\n",
        "x_{21} & x_{22} & \\dots & x_{2p} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "x_{n1} & x_{n2} & \\dots & x_{np}\n",
        "\\end{pmatrix}\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### Conventions:\n",
        "- Bold uppercase ‚Üí matrices (e.g., **X**)  \n",
        "- Bold lowercase ‚Üí vectors of length n (e.g., **a**)  \n",
        "- Normal lowercase ‚Üí scalars or feature vectors  \n",
        "- Random variables ‚Üí capital letters  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "xHR0Uj5WQRYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìñ Organization of the Book\n",
        "\n",
        "### Chapters Overview:\n",
        "\n",
        "1. **Introduction**  \n",
        "2. **Statistical Learning** (KNN + terminology)  \n",
        "3. **Linear Regression**  \n",
        "4. **Classification (Logistic Regression, LDA)**  \n",
        "5. **Resampling (Cross-Validation, Bootstrap)**  \n",
        "6. **Linear Model Selection & Regularization (Lasso, Ridge)**  \n",
        "7. **Non-Linear Models**  \n",
        "8. **Tree Methods (Bagging, Boosting, RF)**  \n",
        "9. **Support Vector Machines**  \n",
        "10. **Deep Learning**  \n",
        "11. **Survival Analysis**  \n",
        "12. **Unsupervised Learning (PCA, Clustering)**  \n",
        "13. **Multiple Hypothesis Testing**\n",
        "\n",
        "Python labs accompany each chapter.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "SYmwBpsuQTI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üóÇÔ∏è Data Sets Used in the Book\n",
        "\n",
        "The ISLP package contains many datasets used in:\n",
        "- exercises  \n",
        "- labs  \n",
        "- visualizations  \n",
        "\n",
        "Examples include:\n",
        "- Wage  \n",
        "- Smarket  \n",
        "- NCI60  \n",
        "- Auto  \n",
        "- Credit  \n",
        "- College  \n",
        "- Default  \n",
        "- USArrests  \n",
        "\n",
        "These datasets cover multiple domains: biology, finance, marketing, sports, and more.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "OCHZXSveQUeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèÅ Summary\n",
        "\n",
        "Chapter 1 provides the foundation for the rest of the book:\n",
        "\n",
        "- What statistical learning is  \n",
        "- Key real-world examples (Regression, Classification, Clustering)  \n",
        "- The history behind modern ML  \n",
        "- The philosophy of the ISLP book  \n",
        "- Types of learning  \n",
        "- Notation used throughout the text  \n",
        "- Overview of all chapters  \n",
        "\n",
        "You are now ready for **Chapter 2 ‚Äî Statistical Learning**, which introduces core ML terminology and the K-Nearest Neighbors method.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "eDmCWGsoQVq7"
      }
    }
  ]
}